import logging
from typing import Optional

from .sources import (
    SourceLoader
)

from .crawler import (
    Crawler
)

from .exceptions import (
    SourceRulesNotLoaded
)

log = logging.getLogger(__name__)

class CrawlerManager():
    def __init__(
        self
    ) -> None:
        """
        Initializes a CrawlerManager instance responsible for managing the 
        crawling process.
        """
        self._sourceloader = SourceLoader()
        self.load_rules()

    def load_rules(
        self
    ) -> None:
        """
        Loads rules and initializes the Crawler instance based on the loaded
        sources.
        Raises `SourceRulesNotLoaded` if no sources are loaded.
        """
        self._sourceloader.load()
        
        if not self._sourceloader.is_loaded:
            raise SourceRulesNotLoaded(
                f"No one source was loaded from {self._sourceloader._rules_dir}"
            )

        self._crawler = Crawler(
            self._sourceloader.sources,
        )

    def crawl_sources(
        self
    ) -> Optional[list]:
        """
        Initiates the crawling process for the loaded sources using the Crawler 
        instance.

        :return: Optional list containing the results of the crawling process.
        """

        self._crawler.crawl() 
        if not self._crawler.is_crawled:
            log.error(
                "None of the sources have been crawled. Check rules, please"
            )
            return
        return self._crawler.result