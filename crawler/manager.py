import logging
from typing import Optional

from crawler.sources import (
    SourceLoader
)

from crawler.crawler import (
    Crawler
)

from crawler.exceptions import (
    SourceRulesNotLoaded
)

log = logging.getLogger(__name__)

class CrawlerManager():
    def __init__(
        self
    ) -> None:
        self._sourceloader = SourceLoader()
        self.load_rules()

    def load_rules(
        self
    ) -> None:
        self._sourceloader.load()
        
        if not self._sourceloader.is_loaded:
            raise SourceRulesNotLoaded(
                f"No one source was loaded from {self._sourceloader._rules_dir}"
            )

        self._crawler = Crawler(
            self._sourceloader.sources,
        )

    def crawl_sources(
        self
    ) -> Optional[list]:
        self._crawler.crawl()
        
        if not self._crawler.is_crawled:
            log.error(
                "None of the sources have been crawled. Check rules"
            )
            return
        
        return self._crawler.result