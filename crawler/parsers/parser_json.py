import logging

from typing import Optional
from json import loads, JSONDecodeError

from crawler.parsers.iparser import (
    IParser
)

from crawler.parsers.utils import (
    search, extract
)

log = logging.getLogger(__name__)

class ParserJson(IParser):
    """An inheritor of the `IParser`, which provides the 
    ability to parse given JSON to the list of the requested 
    fields.

    :param root: root of the data dictionary. From this point
        fields will be searched 

    :param fields: dictionary of correspondence between names 
        of extracted parameters and paths to these parameters
    :type fields: dict

    :param separator: separator in the fields paths
    :type separator: str
    """
    def __init__(
        self,
        fields: dict,
        root: str = None,
        separator: str = "."
    ) -> None:
        """Constructor method."""
        self._fields = fields
        self._root = root
        self._separator = separator

    def parse(
        self,
        data: str
    ) -> Optional[dict]:    
        """This function is the main function of this `Parser`. And, 
        as you can guess, it performs the parsing of JSON content.
        
        :param data: string with the data to be searched for
        :type data: str
                
        :return: data dictionary from the given paths
        :rtype: dict if success, else None
        """

        try:
            data_dict = loads(data)

        except JSONDecodeError as decodeError:
            log.error(
                f"JSONDecodeError: Failed to decode the data into JSON. {decodeError}"
            )
            return
        
        root_dict = search(
            data=data_dict,
            path=self._root,
            separator=self._separator
        )

        parsed_data = extract(
            data=root_dict,
            fields=self._fields,
            separator=self._separator
        )

        return parsed_data